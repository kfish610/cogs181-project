{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "import requests\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from torch.nn import LSTM, Linear, Sigmoid\n",
    "from torch.nn.utils.rnn import pack_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading card data from [Scryfall](https://scryfall.com/), a Magic: The Gathering search engine and data aggregator. We clean the data by removing weirdly formatted cards, as well as cards that contain rarely used characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_raw = pd.read_json('data/scryfall-data.json')\n",
    "\n",
    "# Remove all multi-faced or other weirdly formatted cards\n",
    "cards_raw = cards_raw[cards_raw['layout'] == 'normal']\n",
    "\n",
    "# Remove all digital-only cards\n",
    "cards_raw = cards_raw[~cards_raw['digital']]\n",
    "\n",
    "# Remove all joke cards\n",
    "cards_raw = cards_raw[cards_raw['set_type'] != 'funny']\n",
    "\n",
    "# Remove cards with no text\n",
    "cards_raw = cards_raw[cards_raw['oracle_text'].str.len() > 0]\n",
    "\n",
    "### The next few steps reduce the number of characters we will have to one-hot encode ###\n",
    "# Remove cards that have uncommon characters\n",
    "cards_raw = cards_raw[~cards_raw['oracle_text'].str.contains(r'[!%?úíÉ\\[\\]]')]\n",
    "\n",
    "# Fix index\n",
    "cards_raw = cards_raw.reset_index(drop=True)\n",
    "\n",
    "# Replace \"minus\" with \"hyphen\", as they fulfil the same purpose\n",
    "cards_raw['oracle_text'] = cards_raw['oracle_text'].str.replace('−', '-')\n",
    "\n",
    "# Replace semicolon with comma, as they are close enough\n",
    "cards_raw['oracle_text'] = cards_raw['oracle_text'].str.replace(';', ',')\n",
    "\n",
    "### Generalize card names appearing in rules text ###\n",
    "# This is because the name of the card is irrelevant to its effect, \n",
    "# and cards can even be reprinted with different names\n",
    "def generalize_name(card):\n",
    "    generalized = card.copy()\n",
    "    generalized['oracle_text'] = card['oracle_text'].replace(card['name'], '~')\n",
    "    return generalized\n",
    "\n",
    "cards = cards_raw.apply(generalize_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load data from EDHREC, another data aggregator, which has tags on many cards relating to their purpose (e.g. removing threats, playing more mana, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load EDHREC data; if it doesn't exist, regenerate it\n",
    "try:\n",
    "    edhrec_tags = pd.read_csv('data/edhrec_data.csv', index_col=0)\n",
    "except:\n",
    "    # Replace all special characters with hyphens, other than apostrophes, to match EDHREC format\n",
    "    edhrec_names = cards['name'].str.lower().str.replace('\\'', '').str.replace(r'\\W+', '-', regex=True)\n",
    "\n",
    "    # Split the names into 300 card chunks to fit EDHREC API requirements, then query the API\n",
    "    edhrec_name_chunks = np.array_split(edhrec_names.to_numpy(), range(300, edhrec_names.shape[0], 300))\n",
    "    edhrec_results = [ requests.post('https://edhrec.com/api/cards/', json={'format': 'dict', 'names': list(chunk)}).json()['cards'] for chunk in edhrec_name_chunks ]\n",
    "\n",
    "    # Get the tags for the cards\n",
    "    edhrec_tags = pd.concat([pd.DataFrame(res).T for res in edhrec_results ])['tags']\n",
    "    # Reindex tags based on card name\n",
    "    edhrec_tags = pd.merge(edhrec_names, edhrec_tags, left_on='name', right_index=True)['tags']\n",
    "\n",
    "    # Save to CSV\n",
    "    edhrec_tags.to_csv('data/edhrec_data.csv')\n",
    "\n",
    "# Add the tags to our card data\n",
    "cards_tagged = cards.join(edhrec_tags)\n",
    "# Drop cards with no tags\n",
    "cards_tagged = cards_tagged[~cards_tagged['tags'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the \"Oracle text\" of the cards (the text of the cards under the rules, including errata and updates for uniformity). We convert it into one-hot encoding by characters, then into a packed sequence of tensors for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of each character tensor\n",
    "INPUT_SIZE = 80\n",
    "\n",
    "# Get the frequency of each character in the corpus\n",
    "char_freqs = pd.Series(list(''.join(cards_tagged['oracle_text']))).value_counts()\n",
    "# Ensure we only have 80 characters appearing\n",
    "assert(char_freqs.shape[0] == INPUT_SIZE)\n",
    "\n",
    "# Mapping from a character into its index\n",
    "char_indices = pd.Series(range(80), index=char_freqs.index)\n",
    "\n",
    "# Turn the text of all cards into a packed (jagged) tensor\n",
    "tensor_text = pack_sequence([torch.tensor(np.identity(INPUT_SIZE)[char_indices[list(text)]]) for text in cards_tagged['oracle_text']], enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_tagged['tags']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs181_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
