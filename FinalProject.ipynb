{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from torch.optim.sgd import SGD\n",
    "from torch.nn import Module, LSTM, Linear, Softmax, CrossEntropyLoss\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading card data from [Scryfall](https://scryfall.com/), a Magic: The Gathering search engine and data aggregator. We clean the data by removing weirdly formatted cards, as well as cards that contain rarely used characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_raw = pd.read_json('data/scryfall-data.zip')\n",
    "\n",
    "# Remove all multi-faced or other weirdly formatted cards\n",
    "cards_raw = cards_raw[cards_raw['layout'] == 'normal']\n",
    "\n",
    "# Remove all digital-only cards\n",
    "cards_raw = cards_raw[~cards_raw['digital']]\n",
    "\n",
    "# Remove all joke cards\n",
    "cards_raw = cards_raw[cards_raw['set_type'] != 'funny']\n",
    "\n",
    "# Remove cards with no text\n",
    "cards_raw = cards_raw[cards_raw['oracle_text'].str.len() > 0]\n",
    "\n",
    "### The next few steps reduce the number of characters we will have to one-hot encode ###\n",
    "# Remove cards that have uncommon characters\n",
    "cards_raw = cards_raw[~cards_raw['oracle_text'].str.contains(r'[!%?úíÉ\\[\\]]')]\n",
    "\n",
    "# Fix index\n",
    "cards_raw = cards_raw.reset_index(drop=True)\n",
    "\n",
    "# Replace \"minus\" with \"hyphen\", as they fulfil the same purpose\n",
    "cards_raw['oracle_text'] = cards_raw['oracle_text'].str.replace('−', '-')\n",
    "\n",
    "# Replace semicolon with comma, as they are close enough\n",
    "cards_raw['oracle_text'] = cards_raw['oracle_text'].str.replace(';', ',')\n",
    "\n",
    "### Generalize card names appearing in rules text ###\n",
    "# This is because the name of the card is irrelevant to its effect, \n",
    "# and cards can even be reprinted with different names\n",
    "def generalize_name(card):\n",
    "    generalized = card.copy()\n",
    "    generalized['oracle_text'] = card['oracle_text'].replace(card['name'], '~')\n",
    "    return generalized\n",
    "\n",
    "cards = cards_raw.apply(generalize_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load data from EDHREC, another data aggregator, which has tags on many cards relating to their purpose (e.g. removing threats, playing more mana, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kfish\\AppData\\Local\\Temp\\ipykernel_14580\\3858669450.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  edhrec_tags = pd.read_csv('data/edhrec_data.csv', index_col=0).applymap(literal_eval, na_action='ignore')\n"
     ]
    }
   ],
   "source": [
    "# Try to load EDHREC data; if it doesn't exist, regenerate it\n",
    "try:\n",
    "    edhrec_tags = pd.read_csv('data/edhrec_data.csv', index_col=0).applymap(literal_eval, na_action='ignore')\n",
    "except:\n",
    "    # Replace all special characters with hyphens, other than apostrophes, to match EDHREC format\n",
    "    edhrec_names = cards['name'].str.lower().str.replace('\\'', '').str.replace(r'\\W+', '-', regex=True)\n",
    "\n",
    "    # Split the names into 300 card chunks to fit EDHREC API requirements, then query the API\n",
    "    edhrec_name_chunks = np.array_split(edhrec_names.to_numpy(), range(300, edhrec_names.shape[0], 300))\n",
    "    edhrec_results = [ requests.post('https://edhrec.com/api/cards/', json={'format': 'dict', 'names': list(chunk)}).json()['cards'] for chunk in edhrec_name_chunks ]\n",
    "\n",
    "    # Get the tags for the cards\n",
    "    edhrec_tags = pd.concat([pd.DataFrame(res).T for res in edhrec_results ])['tags']\n",
    "    # Reindex tags based on card name\n",
    "    edhrec_tags = pd.merge(edhrec_names, edhrec_tags, left_on='name', right_index=True)['tags']\n",
    "\n",
    "    # Save to CSV\n",
    "    edhrec_tags.to_csv('data/edhrec_data.csv')\n",
    "\n",
    "# Add the tags to our card data\n",
    "cards_tagged = cards.join(edhrec_tags)\n",
    "# Drop cards with no tags\n",
    "cards_tagged = cards_tagged[~cards_tagged['tags'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the \"Oracle text\" of the cards (the text of the cards under the rules, including errata and updates for uniformity). We convert it into one-hot encoding by characters, then into a packed sequence of tensors for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of each character tensor\n",
    "INPUT_SIZE = 80\n",
    "\n",
    "# Get the frequency of each character in the corpus\n",
    "char_freqs = pd.Series(list(''.join(cards_tagged['oracle_text']))).value_counts()\n",
    "# Ensure we only have 80 characters appearing\n",
    "assert(char_freqs.shape[0] == INPUT_SIZE)\n",
    "\n",
    "# Mapping from a character into its index\n",
    "char_indices = pd.Series(range(INPUT_SIZE), index=char_freqs.index)\n",
    "\n",
    "# Turn the text of all cards into a packed (jagged) tensor\n",
    "tensor_text = [ torch.tensor(np.identity(INPUT_SIZE)[char_indices[list(text)]]).float() for text in cards_tagged['oracle_text'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we load the tags into a tensor to be our labels/training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_SIZE = 7\n",
    "\n",
    "# Get the frequencies of each category\n",
    "tag_freqs = cards_tagged['tags'].explode().value_counts()\n",
    "# Ensure we only have 7 categories\n",
    "assert(tag_freqs.shape[0] == OUTPUT_SIZE)\n",
    "\n",
    "# Mapping from a tag into its index\n",
    "tag_indices = pd.Series(range(OUTPUT_SIZE), index=tag_freqs.index)\n",
    "\n",
    "# One-hot encoding, but with the possibility of multiple categories\n",
    "tensor_tags = [ torch.tensor(np.identity(OUTPUT_SIZE)[tag_indices[tags]].mean(axis=0)).float() for tags in cards_tagged['tags'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the model, consisting of an LSTM layer, followed by a linear layer and a sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTGClassifier(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, layers):\n",
    "        super(MTGClassifier, self).__init__()\n",
    "        self.input_size, self.hidden_size, self.output_size = input_size, hidden_size, output_size\n",
    "\n",
    "        self.lstm = LSTM(input_size, hidden_size, layers)\n",
    "        self.linear = Linear(hidden_size, output_size)\n",
    "        self.activation = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, _ = self.lstm(input)\n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\tError: 0.16999254810571088\n",
      "Epoch: 1\n",
      "\tError: 0.1699915315069998\n",
      "Epoch: 2\n",
      "\tError: 0.1699905284389827\n",
      "Epoch: 3\n",
      "\tError: 0.1699895390872905\n",
      "Epoch: 4\n",
      "\tError: 0.16998856292726217\n",
      "Epoch: 5\n",
      "\tError: 0.16998759950874903\n",
      "Epoch: 6\n",
      "\tError: 0.1699866490674485\n",
      "Epoch: 7\n",
      "\tError: 0.16998571099621862\n",
      "Epoch: 8\n",
      "\tError: 0.16998478527707536\n",
      "Epoch: 9\n",
      "\tError: 0.1699838715550741\n",
      "Epoch: 10\n",
      "\tError: 0.16998296960680867\n",
      "Epoch: 11\n",
      "\tError: 0.16998207954960587\n",
      "Epoch: 12\n",
      "\tError: 0.16998120054681248\n",
      "Epoch: 13\n",
      "\tError: 0.1699803327713402\n",
      "Epoch: 14\n",
      "\tError: 0.169979475874929\n",
      "Epoch: 15\n",
      "\tError: 0.16997862983468176\n",
      "Epoch: 16\n",
      "\tError: 0.16997779448635666\n",
      "Epoch: 17\n",
      "\tError: 0.1699769695443203\n",
      "Epoch: 18\n",
      "\tError: 0.16997615469765862\n",
      "Epoch: 19\n",
      "\tError: 0.16997534966874278\n",
      "Epoch: 20\n",
      "\tError: 0.16997455459906646\n",
      "Epoch: 21\n",
      "\tError: 0.16997376910228895\n",
      "Epoch: 22\n",
      "\tError: 0.1699729932279079\n",
      "Epoch: 23\n",
      "\tError: 0.1699722264752079\n",
      "Epoch: 24\n",
      "\tError: 0.1699714684822162\n",
      "Epoch: 25\n",
      "\tError: 0.16997071975653663\n",
      "Epoch: 26\n",
      "\tError: 0.1699699795025247\n",
      "Epoch: 27\n",
      "\tError: 0.16996924787744846\n",
      "Epoch: 28\n",
      "\tError: 0.1699685243061994\n",
      "Epoch: 29\n",
      "\tError: 0.16996780935302994\n",
      "Epoch: 30\n",
      "\tError: 0.16996710244193272\n",
      "Epoch: 31\n",
      "\tError: 0.1699664029237658\n",
      "Epoch: 32\n",
      "\tError: 0.16996571129800914\n",
      "Epoch: 33\n",
      "\tError: 0.16996502706706668\n",
      "Epoch: 34\n",
      "\tError: 0.16996435039662894\n",
      "Epoch: 35\n",
      "\tError: 0.16996368081953378\n",
      "Epoch: 36\n",
      "\tError: 0.1699630183686004\n",
      "Epoch: 37\n",
      "\tError: 0.16996236238661883\n",
      "Epoch: 38\n",
      "\tError: 0.16996171344678002\n",
      "Epoch: 39\n",
      "\tError: 0.1699610708392101\n",
      "Epoch: 40\n",
      "\tError: 0.16996043462376656\n",
      "Epoch: 41\n",
      "\tError: 0.16995980469528627\n",
      "Epoch: 42\n",
      "\tError: 0.16995918081535455\n",
      "Epoch: 43\n",
      "\tError: 0.1699585628960633\n",
      "Epoch: 44\n",
      "\tError: 0.16995795071377756\n",
      "Epoch: 45\n",
      "\tError: 0.1699573439598713\n",
      "Epoch: 46\n",
      "\tError: 0.1699567427086348\n",
      "Epoch: 47\n",
      "\tError: 0.16995614674893017\n",
      "Epoch: 48\n",
      "\tError: 0.16995555602671858\n",
      "Epoch: 49\n",
      "\tError: 0.1699549701225314\n",
      "Epoch: 50\n",
      "\tError: 0.16995438905712884\n",
      "Epoch: 51\n",
      "\tError: 0.16995381245251373\n",
      "Epoch: 52\n",
      "\tError: 0.1699532403301573\n",
      "Epoch: 53\n",
      "\tError: 0.1699526727793725\n",
      "Epoch: 54\n",
      "\tError: 0.16995210951617515\n",
      "Epoch: 55\n",
      "\tError: 0.16995155045811763\n",
      "Epoch: 56\n",
      "\tError: 0.16995099506773056\n",
      "Epoch: 57\n",
      "\tError: 0.1699504436402664\n",
      "Epoch: 58\n",
      "\tError: 0.16994989561343765\n",
      "Epoch: 59\n",
      "\tError: 0.16994935109728593\n",
      "Epoch: 60\n",
      "\tError: 0.16994880989581831\n",
      "Epoch: 61\n",
      "\tError: 0.16994827189773493\n",
      "Epoch: 62\n",
      "\tError: 0.16994773699204888\n",
      "Epoch: 63\n",
      "\tError: 0.16994720490493878\n",
      "Epoch: 64\n",
      "\tError: 0.1699466754972629\n",
      "Epoch: 65\n",
      "\tError: 0.1699461488476673\n",
      "Epoch: 66\n",
      "\tError: 0.1699456245263227\n",
      "Epoch: 67\n",
      "\tError: 0.1699451025902143\n",
      "Epoch: 68\n",
      "\tError: 0.1699445826829618\n",
      "Epoch: 69\n",
      "\tError: 0.16994406505675205\n",
      "Epoch: 70\n",
      "\tError: 0.16994354912987103\n",
      "Epoch: 71\n",
      "\tError: 0.1699430349818843\n",
      "Epoch: 72\n",
      "\tError: 0.16994252253079628\n",
      "Epoch: 73\n",
      "\tError: 0.16994201154225938\n",
      "Epoch: 74\n",
      "\tError: 0.16994150183546836\n",
      "Epoch: 75\n",
      "\tError: 0.16994099315233907\n",
      "Epoch: 76\n",
      "\tError: 0.16994048580480065\n",
      "Epoch: 77\n",
      "\tError: 0.16993997914775869\n",
      "Epoch: 78\n",
      "\tError: 0.1699394733795085\n",
      "Epoch: 79\n",
      "\tError: 0.1699389678591898\n",
      "Epoch: 80\n",
      "\tError: 0.16993846304595775\n",
      "Epoch: 81\n",
      "\tError: 0.16993795837166456\n",
      "Epoch: 82\n",
      "\tError: 0.16993745435352128\n",
      "Epoch: 83\n",
      "\tError: 0.16993695004748574\n",
      "Epoch: 84\n",
      "\tError: 0.16993644576934183\n",
      "Epoch: 85\n",
      "\tError: 0.1699359409937558\n",
      "Epoch: 86\n",
      "\tError: 0.16993543583399845\n",
      "Epoch: 87\n",
      "\tError: 0.1699349301828424\n",
      "Epoch: 88\n",
      "\tError: 0.16993442377952706\n",
      "Epoch: 89\n",
      "\tError: 0.16993391655248002\n",
      "Epoch: 90\n",
      "\tError: 0.16993340847708083\n",
      "Epoch: 91\n",
      "\tError: 0.16993289881071985\n",
      "Epoch: 92\n",
      "\tError: 0.16993238815655373\n",
      "Epoch: 93\n",
      "\tError: 0.16993187611166186\n",
      "Epoch: 94\n",
      "\tError: 0.1699313624090088\n",
      "Epoch: 95\n",
      "\tError: 0.169930846814523\n",
      "Epoch: 96\n",
      "\tError: 0.16993032935401983\n",
      "Epoch: 97\n",
      "\tError: 0.1699298096808008\n",
      "Epoch: 98\n",
      "\tError: 0.16992928771156615\n",
      "Epoch: 99\n",
      "\tError: 0.16992876371213456\n",
      "Epoch: 100\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 60\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = MTGClassifier(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, 2)\n",
    "\n",
    "# Inversely weight the categories, so that we don't get too much focus on the largest one\n",
    "inverse_freqs = 1/tag_freqs\n",
    "weights = inverse_freqs/inverse_freqs.sum()\n",
    "loss_func = CrossEntropyLoss(weight=torch.tensor(weights.to_numpy()))\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "# Split data into 80/20 train/test\n",
    "text_tagged = list(zip(tensor_text, tensor_tags))\n",
    "train_data, test_data = random_split(text_tagged, [ 0.8, 0.2 ])\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "losses = np.zeros((N_EPOCHS, len(train_data)))\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for i, (text, tags) in enumerate(train_data):\n",
    "        # Clear accumulated gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate probabilities from sequence\n",
    "        probabilities = model(text)\n",
    "\n",
    "        loss = loss_func(probabilities[-1], tags)\n",
    "        losses[epoch, i] = loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"\\tError:\", losses[epoch].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
